{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed28825a-43e7-4a84-9714-501a5828b5b5",
   "metadata": {},
   "source": [
    "# PS3 Submission\n",
    "Riccardo Fiorista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d91d0-820f-4f76-9164-19982d0ea4ba",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### a)\n",
    "Our one-level optimization formulation is based on the capacity expansion planning to allow for maximum-flow in different scenarios $\\omega \\in \\Omega$ where :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{array}{ll@{}lll}\n",
    "\\underset{\\boldsymbol{\\boldsymbol{x,y}}}{\\text{max}}       & \\quad \\sum\\limits_{\\omega \\in \\Omega}\\displaystyle \\pi_\\omega y^\\omega_{ts} &\\\\\n",
    "\\text{subject to} & \\sum\\limits_{\\{j \\in N \\mid(i, j) \\in E\\}} y_{i j}-\\sum\\limits_{\\{j \\in N \\mid(j, i) \\in E\\}} y_{j i}=0 & \\forall i \\in N \\backslash\\{s, t\\} \\\\\n",
    "                  & \\sum\\limits_{\\{j \\in N \\mid(s, j) \\in E\\}} y_{s j}-\\sum\\limits_{\\{j \\in N \\mid(j, s) \\in E\\}} y_{j s}-y_{t s}=0 & \\\\\n",
    "                  & \\sum\\limits_{\\{j \\in N \\mid(t, j) \\in E\\}} y_{t j}-\\sum\\limits_{\\{j \\in N \\mid(j, t) \\in E\\}} y_{j t}+y_{t s}=0 & \\\\\n",
    "                  & y_{ij} \\leq u_{ij} + x^{\\text{fixed}}_{ij}-d^\\omega_{ij} & \\forall (i,j)\\in E\\\\\n",
    "                  & \\sum\\limits_{(i,j) \\in E} x^{\\text{fixed}}_{ij} \\leq \\boldsymbol{B}\\\\\n",
    "                  & x^{\\text{fixed}}_{ij}, y_{ij} \\in \\mathbb{R}_{\\geq 0}& \\forall(i, j) \\in E\n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "Where:\n",
    "\n",
    "\\begin{alignat*}{3}\n",
    "      &G=\\langle V, E \\rangle &\\dots\\dots\\quad & \\text{Graph}\\\\\n",
    "      &V       &\\dots\\dots\\quad & \\text{ Set of nodes } \\\\\n",
    "      &E       &\\dots\\dots\\quad & \\text{ Set of edges } \\\\\n",
    "      &(i,j)   &\\dots\\dots\\quad & \\text{ Edge from node } i\\in V \\text{ to node } j\\in V \\text{ such that } (i,j)\\in E\\\\\n",
    "      &y_{ij}  &\\dots\\dots\\quad & \\text{ Flow on arc (i,j)}  \\\\\n",
    "      &s       &\\dots\\dots\\quad & \\text{ Source node}  \\\\\n",
    "      &t       &\\dots\\dots\\quad & \\text{ Target node}  \\\\\n",
    "      &\\Omega       &\\dots\\dots\\quad & \\text{ Set of possible (in our case \\textit{discrete} scenarios }  \\\\      \n",
    "      &\\omega\\in\\Omega       &\\dots\\dots\\quad & \\text{ a specific realization event from } \\Omega  \\\\\n",
    "      &d^{\\omega}_{ij}   &\\dots\\dots\\quad & \\text{ The capacity drop instantiated by the event } \\omega\\in\\Omega \\\\\n",
    "      &y_{ts}  &\\dots\\dots\\quad & \\text{ Artificial edge from sink node } t \\text{ to source node } s\\\\\n",
    "      &u_{ij}\\in \\mathbb{R}_{\\geq 0}  &\\dots\\dots\\quad & \\text{ Capacity of arc (i,j)}  \\\\\n",
    "      &x^{\\text{fixed}}_{ij}\\in \\mathbb{R}_{\\geq 0}  &\\dots\\dots\\quad & \\text{ Capacity \\textbf{expansion} of arc (i,j) which, in this sub-problem is \\textbf{fixed}}  \\\\\n",
    "      &\\boldsymbol{B} &\\dots\\dots\\quad & \\text{ Expansion budget}\n",
    "\\end{alignat*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469500cb-3575-4e6a-a7ae-68244bc2b563",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6efcb9-17d2-41b3-b63f-9df9afb97259",
   "metadata": {},
   "source": [
    "Formalization as a two-stage stochastic LP:\n",
    "\n",
    "\\begin{array}{cll}\n",
    "\\underset{\\boldsymbol{\\boldsymbol{\\boldsymbol{x}}}}{\\text{max}}   & \\mathbb{E}_{\\xi} \\left[\\mathcal{Q}(x, \\xi(\\omega) \\right] & \\\\\n",
    "\\text { subject to } & \\sum\\limits_{(i,j) \\in E} x_{ij} \\leq \\boldsymbol{B} & \\\\\n",
    "                     & x_{ij}\\in \\mathbb{R}_\\geq 0\n",
    "\\end{array}\n",
    "\n",
    "As we are considering a discrete set of events $\\Omega$, where each event occurs with a certain probability $\\pi_\\omega$, we can reformualte the above as:\n",
    "\n",
    "\\begin{array}{cll}\n",
    "\\underset{\\boldsymbol{\\boldsymbol{\\boldsymbol{x}}}}{\\text{max}}   & \\textcolor{red}{\\sum\\limits_{\\omega \\in \\Omega} \\pi^\\omega \\mathcal{Q}(x, \\xi(\\omega)} & \\\\\n",
    "\\text { subject to } & \\sum\\limits_{(i,j) \\in E} x_{ij} \\leq \\boldsymbol{B} & \\\\\n",
    "                     & x_{ij}\\in \\mathbb{R}_\\geq 0\n",
    "\\end{array}\n",
    "\n",
    "The part in red will be the definition of our second-stage problem $\\textcolor{red}{\\text{z}}$.\n",
    "Thus, for a given scenario $\\omega \\in \\Omega$, we have:\n",
    "\n",
    "\\begin{array}{cll}\n",
    "\\textcolor{red}{z =} \\mathcal{Q}\\left(\\boldsymbol{x},\\xi(\\omega)\\right) =& \\underset{\\boldsymbol{\\boldsymbol{\\boldsymbol{\\boldsymbol{y}^\\omega}}}}{\\text{max}} \\quad y^\\omega_{ts} & \\\\\n",
    "\\text{subject to} & \\sum\\limits_{\\{j \\in N \\mid(i, j) \\in E\\}} y^\\omega_{i j}-\\sum\\limits_{\\{j \\in N \\mid(j, i) \\in E\\}} y^\\omega_{j i}=0 & \\forall i \\in N \\backslash\\{s, t\\} \\\\\n",
    "                  & \\sum\\limits_{\\{j \\in N \\mid(s, j) \\in E\\}} y^\\omega_{s j}-\\sum\\limits_{\\{j \\in N \\mid(j, s) \\in E\\}} y^\\omega_{j s}-y^\\omega_{t s}=0 & \\\\\n",
    "                  & \\sum\\limits_{\\{j \\in N \\mid(t, j) \\in E\\}} y^\\omega_{t j}-\\sum\\limits_{\\{j \\in N \\mid(j, t) \\in E\\}} y^\\omega_{j t}+y^\\omega_{t s}=0 & \\\\\n",
    "                  & y^\\omega_{ij} \\leq u_{ij} + x_{ij} - d^\\omega_{ij} & \\forall (i,j)\\in E\\\\\n",
    "                  & \\sum\\limits_{(i,j) \\in E} x_{ij} \\leq \\boldsymbol{B}\\\\\n",
    "                  & x_{ij}, y^\\omega_{ij} \\in \\mathbb{R}_{\\geq 0}& \\forall(i, j) \\in E\n",
    "\\end{array}\n",
    "\n",
    "As we want to apply Bender's decomposition, we are required to take the dual of the second-stage problem, $\\textbf{z}$, which we refer to as $\\textbf{z}^\\prime$.\n",
    "The dual is then:\n",
    "\n",
    "\\begin{array}{cll}\n",
    "\\textcolor{red}{z^\\prime =} \\underset{\\boldsymbol{\\boldsymbol{\\alpha^\\omega, \\theta^\\omega}}}{\\text{min}}   & \\sum\\limits_{(i, j) \\in E}\\left(u_{i j}+x_{ij}-d^\\omega_{ij}\\right) \\theta^\\omega_{i j} & \\\\\n",
    "\\text { subject to }    & \\alpha^\\omega_i-\\alpha^\\omega_j+\\theta_{i j} \\geq 0, & \\forall(i, j) \\in E \\\\\n",
    "                        & \\alpha^\\omega_t-\\alpha^\\omega_s \\geq 1 & \\\\\n",
    "                        & \\theta^\\omega_{i j} \\geq 0, & \\forall(i, j) \\in E\\\\\n",
    "                        & x_{ij}, u_{ij} \\in \\mathbb{R}_{\\geq 0}& \\forall(i, j) \\in E\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767ba80-38ee-4521-bfbc-4c5c7c39c7bd",
   "metadata": {},
   "source": [
    "### c)\n",
    "- Necessary Conditions:\n",
    "    - Existence of negative coefficients in the objective function: The term $\\left(u_{i j}+x_{ij}-d^\\omega_{ij}\\right)$ in the objective can become *negative*.\n",
    "    - Furthermore, we have that $\\theta^\\omega_{ij}$ can increase indefinitely as we only constrain it to be $d^\\omega_{ij}\\geq 0$.\n",
    "- Sufficient Conditions:\n",
    "    - If $d^\\omega_{ij}\\geq \\left(u_{i j}+x_{ij}\\right)$, then the term $\\left(u_{i j}+x_{ij}-d^\\omega_{ij}\\right) < 0$ and thus $\\theta^\\omega_{ij}\\rightarrow \\infty$ as we minimize. Hence, with this sufficient condition, we have an unbounded dual.\n",
    "\n",
    "In summary, we can say that, for $z^\\prime$ to be unbounded, we require the constraint $\\left(u_{i j}+x_{ij}\\right)-d^\\omega_{ij}<0$ which is both necessary for the dual $z^\\prime$ to be unbounded as well as sufficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e44483-c8d8-4e96-9e2d-87a34a47e632",
   "metadata": {},
   "source": [
    "### d)\n",
    "Thus, we add the constraint $$u_{ij}+x_{ij}-d^\\omega_{ij}\\geq 0; \\forall (i,j)\\in E, \\forall\\omega \\in \\Omega$$. With this constrinat, we ensure, that the drop of capacity $d^\\omega_{ij}$ cannot exceeed the edge's capacity $u_{ij}$ or extended capacity $u_{ij}+x_{ij}$ if $x_{ij}>0$. This is without loss of generality since negative capacities after a drop are not defined / carry no connotation in the real world.\n",
    "\n",
    "In other words, we have found an extreme ray $\\boldsymbol{w}$ which makes the objective infinite. Thus, we add the constraint $\\boldsymbol{w}^{\\omega^\\intercal}(u_{ij}+x_{ij}-d^\\omega_{ij})$ to the master problem to guarantee feasibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ee59f-120e-497f-8648-4ddfe10ed72e",
   "metadata": {},
   "source": [
    "### e)\n",
    "Indeed, we now begin our Bender's algorithm iteration with $|E|\\times|\\Omega|$ constraints. However, we effectively only need $|E|$ additional constraints if we consider, that we only require to lowerbound the maximum $d_{ij}^\\omega$ which we consider over all scenarios $\\omega \\in \\Omega$. Thus, we argue to add the following constraints:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\{u_{ij}+x_{ij}\\geq \\max\\limits_{\\omega} d^\\omega_{ij} \\text{ };\\text{ }\\forall \\omega \\in \\Omega\\}^{|E|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f68b7f-a1cb-46fb-a999-0c24fd420192",
   "metadata": {},
   "source": [
    "### f) \n",
    "\n",
    "To detail the Bender's decomoposition algorithm, we first define the Master Problem (MP):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{array}{ll@{}lll}\n",
    "\\underset{\\boldsymbol{\\boldsymbol{x}^l, \\boldsymbol{\\gamma}^l}}{\\text{max}}       & \\quad\\displaystyle \\sum\\limits_{(i,j)\\in E} x^l_{ij} + \\sum\\limits_{\\omega \\in \\Omega} \\pi_\\omega \\gamma^l_\\omega&\\\\\n",
    "\\text{subject to}   & \\sum\\limits_{(i,j) \\in E} x^l_{ij} \\leq \\boldsymbol{B}\\\\\n",
    "                    & \\textcolor{Cerulean}{\\gamma^l_\\omega \\leq \\gamma^0}                                                                     & \\textcolor{Cerulean}{\\forall \\omega\\in \\Omega}\\\\\n",
    "                    & \\textcolor{Bittersweet}{\\gamma^l_\\omega \\leq \\left(u_{ij} + x^l_{ij} - {}^ld^\\omega_{ij}\\right) {}^k\\theta^\\omega_{ij}} & \\textcolor{Bittersweet}{\\forall (i,j) \\in E, \\forall \\omega \\in \\Omega}\\\\\n",
    "                    & \\textcolor{OliveGreen}{u_{ij}+x_{ij}\\geq \\max\\limits_{\\omega} {}^0d^\\omega_{ij}}                                       & \\textcolor{OliveGreen}{\\forall (i,j) \\in E}\\\\\n",
    "                    & x^l_{ij}, {}^k\\theta^\\omega_{ij} \\in \\mathbb{R}_{\\geq 0}                                                                & \\forall (i,j) \\in E\\\\\n",
    "                    & \\forall k = 1, \\dots, l-1\n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "Here, we introduce auxiliary variable $\\gamma^l_\\omega$ which represents the objective function of the subproblem $z$ in iteration $l$ of the Bender's algorithm and for scenario $\\omega$. We define the constraints of the MP to include the constraints of the first level problem, i.e. the capacity extension allocation. To provide an upper-bound to $\\gamma$ in the first iteration of the algorithm, we introduce the constraint $\\textcolor{Cerulean}{\\gamma^l_\\omega \\leq \\gamma^0  \\textrm{ };\\textrm{ } \\forall \\omega\\in \\Omega}$, where $\\gamma^0$ is a reasonably large number to bound $\\gamma$. For each subsequent iteration, we add a Bender's cut which is the brown constraint above, $\\textcolor{Bittersweet}{\\gamma^l_\\omega \\leq \\left(u_{ij} + x^l_{ij} - {}^ld^\\omega_{ij}\\right) {}^k\\theta^\\omega_{ij} \\textrm{ };\\textrm{ } \\forall (i,j) \\in E, \\forall \\omega \\in \\Omega}$. Finally, in order to guarantee boundedness of the objective function of the sub-problem, we also add the previously identified constraint (here in green), $\\textcolor{OliveGreen}{u_{ij}+x_{ij}\\geq \\max\\limits_{\\omega} {}^0d^\\omega_{ij}  \\textrm{ };\\textrm{ } \\forall (i,j) \\in E}$, where ${}^0d^\\omega_{ij}$ indicates, that this is a set of constraints that we impose during at the problem's initialization.\n",
    "\n",
    "The sub-problem is then $\\textcolor{red}{z}$ or, more precisely, its dual $\\textcolor{red}{z^\\prime}$ as defined in **b)**.\n",
    "\n",
    "0) **Initialization:** We set $l=0$, $x^{\\text{fixed} (l)}=x^{\\text{initial}}$, and Lower Bound $\\text{LB}=-\\infty$. Here, $x^{\\text{fixed} (l)}$ is the value of $\\boldsymbol{x}^{l}$ at iteration $l$ which we fix to solve the sub-problem. Initialize the problem with the constraints we identified above.\n",
    "\n",
    "1) **Solve Subproblem:** We now obtain the values of all dual variables (sensitivities), and the value of the objective function, which becomes the Upper Bound ($\\text{LB}$). In order to solve the maximum-flow sub-problem, I would use the Ford-Fulkerson algorithm.\n",
    "\n",
    "2) **Convergence Check:** If $|\\text{UB}-\\text{LB}|\\leq \\epsilon$ where $\\epsilon$ is a sufficiently small tolerance constant (e.g. $10^{-4}$, then the optimal solution with a level of accuracty $\\epsilon$ is obtaines, otherwise we set $l \\leftarrow l+1$ and follow with the subsequent iteration.\n",
    "\n",
    "3) **Solve Master Problem:** We obtain the updated $x^{(l)}$ and set $\\text{LB} \\leftarrow \\gamma^{(l)}$ and go to *Step 1* with the updated $x^{\\text{fixed} (l)}$.\n",
    "\n",
    "The above algorithm is inspired by Jalal Kazempour's lecture on Bender's decomposition which he held at the Technical University of Denmark ([link](https://drive.google.com/file/d/1s9YDTVG8USv8dsfQt3YubiQw5WtREGII/view))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e27fdd-efcf-414b-b47e-85f0b5a01654",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "### a)\n",
    "Let $S$ be the set of all possible scenarios with corresponding probabilities $\\alpha_s$.\n",
    "\n",
    "Then, let $z(x, \\xi, S')$ be the objective value of an arbitrary stochastic program where:\n",
    "\n",
    "- $x$ represents the first stage decision variable\n",
    "- $\\xi$ represents the stochastic parameters\n",
    "- $S^\\prime \\subseteq S$ is the subset of scenarios\n",
    "\n",
    "The EVPI is then defined as $z^* - \\theta$ where we essentially have \n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta = \\mathbb{E} \\left[ z(x, \\xi, S) \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Thus, by definition of an expectation, we have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbb{E}_S \\left[ z(x, \\xi, S) \\right] = \\sum_{s \\in S'} \\alpha_s \\cdot z(x, \\xi, s)\n",
    "\\end{equation}\n",
    "\n",
    "If for every scenario $s \\in S$ we have that $z(x, \\xi, s) = z^*(x, \\xi, s)$ then\n",
    "\n",
    "\\begin{equation}\n",
    "    \\theta = \\mathbb{E}_S \\left[ z(x, \\xi, S) \\right] = \\sum_{s \\in S'} \\alpha_s \\cdot z(x, \\xi, s) = z^*(x, \\xi, S)\n",
    "\\end{equation}\n",
    "\n",
    "as $ \\sum_{s \\in S'} \\alpha_s = 1 $ and thus we have:\n",
    "\n",
    "\\begin{equation}\n",
    "    EVPI = z^* - \\theta = z^*-z^* = 0\n",
    "\\end{equation}\n",
    "\n",
    "As $ z^*(x, \\xi, S) \\geq z(x, \\xi, s) $, in the case of a maximization problem, we have that\n",
    "\n",
    "\\begin{equation}\n",
    "    EVPI = z^* - \\theta \\geq 0\n",
    "\\end{equation}\n",
    "\n",
    "This reasoning holds also for the normalized EVPI (nEVPI) formulation as it simply just scales $\\theta$ to a $[0,1]$ range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345eddc8-83c3-45cd-abd7-f608a1682466",
   "metadata": {},
   "source": [
    "### b)\n",
    "See the code in the appendix. We calculated the EVPI by applying the algorithm provided and reached the following result for 6 locations, 10 days, and 20 scenarios:\n",
    "\n",
    "z_star=3081715612.0604277\n",
    "EVPI: 0.2980171693261971\n",
    "\n",
    "\\begin{align*}\n",
    "    z^* =& \\quad 3081715612.0604277\\\\\n",
    "    \\theta =& \\left(\\frac{1}{20}\\right) * 2037038385.0777445\\\\\n",
    "   &+2243750585.077387\\\\\n",
    "   &+2360439461.329098\\\\\n",
    "   &+2293138364.6387243\\\\\n",
    "   &+2207392466.1410875\\\\\n",
    "   &+2265022647.2333407\\\\\n",
    "   &+2190595835.766714\\\\\n",
    "   &+2087950689.2352629\\\\\n",
    "   &+1969955502.65166\\\\\n",
    "   &+2375452711.575093\\\\\n",
    "   &+1840320394.7999904\\\\\n",
    "   &+2153133336.7469225\\\\\n",
    "   &+2156836458.4782643\\\\\n",
    "   &+2346067649.719794\\\\\n",
    "   &+2135729904.3902342\\\\\n",
    "   &+2059093605.612205\\\\\n",
    "   &+2210056734.9514804\\\\\n",
    "   &+2076375601.0461044\\\\\n",
    "   &+2313644053.261371\\\\\n",
    "   &+1944234585.98413\\\\\n",
    "    \\textrm{EVPI} =& \\quad\\frac{z^*-\\theta}{z^*} = \\boldsymbol{0.2980171693261971}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc44f13-f5a9-4792-a6b2-24353f92bbfe",
   "metadata": {},
   "source": [
    "### c)\n",
    "See the code in the appendix. We calculated the SVV by applying the algorithm provided and reached the following result for 6 locations, 10 days, and 20 scenarios:\n",
    "\n",
    "\\begin{align*}\n",
    "    z^* =& \\quad 3081715612.0604277\\\\\n",
    "    \\theta =&\\quad 20\\left(\\frac{1}{20}\\right) * 8919553111.93422\\\\\n",
    "            & +8955429047.764408\\\\\n",
    "            & +12938016508.927963\\\\\n",
    "            & +11915455055.01068\\\\\n",
    "            & +12507005476.357182\\\\\n",
    "            & +9271072306.352892\\\\\n",
    "            & +15392746178.222075\\\\\n",
    "            & +10345518048.841034\\\\\n",
    "            & +13462946883.018383\\\\\n",
    "            & +16345091514.22208\\\\\n",
    "            & +10127855081.980455\\\\\n",
    "            & +10531286752.773281\\\\\n",
    "            & +6010850083.619574\\\\\n",
    "            & +11511341494.684628\\\\\n",
    "            & +13967243245.460955\\\\\n",
    "            & +7742094524.11655\\\\\n",
    "            & +11053177975.691175\\\\\n",
    "            & +7175127230.518453\\\\\n",
    "            & +15345258515.802065\\\\\n",
    "            & +6586100939.777442\\\\\n",
    "    \\textrm{SVV}= & \\quad\\frac{\\theta-z^*}{z^*} = \\boldsymbol{2.5711142376942933}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f280b7b-8c2f-430f-b255-16ce8ca8a296",
   "metadata": {},
   "source": [
    "### d)\n",
    "\n",
    "<center><img width=500 src=\"img/run_1701730122.8202505.svg\"/></center>\n",
    "\n",
    "The results above shows the behavior of the Expected Value of Perfect Information (EVPI) and the Value of Stochastic Solution (VSS) over an increasing number of scenarios, from 10 to 40. The two respective questions, these values attempt to answer are:\n",
    "\n",
    "- [EVPI] How much can we expect the solution to improve on average if we had perfect information?\n",
    "- [VSS] How much can we expect the solution to improve on average if we use the stochastic solution?\n",
    "\n",
    "Thus, we see, that in general, any number of scenarios would quasi-equally benefit from PI. However, while PI is amiss, we find that the benefit brought by the stochastic approach significantly outweights the deterministic one. While the latter only consider the average of the stochastic parameters, the stochastic solution quantifies the uncertainty the planner has and incorporates the variance in the solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7f89e-b628-4267-8a99-d29325f5ae9b",
   "metadata": {},
   "source": [
    "## Problem 3 (Midterm Problem 2: Hide-and-Seek (The Return))\n",
    "### a) (7 points) \n",
    "**Question**\n",
    "\n",
    "Let $M \\subseteq E$ be a matching of $G$. Derive a mixed strategy $\\sigma^{2^*}$ for player 2 that randomizes over the safe-houses in $M$ such that the probability with which player 2 is detected is at most $\\frac{1}{\\sum_{(i, j) \\in M} 1 / p_{i j}}$, regardless of player 1's strategy. Equivalently, find $\\sigma^{2^*} \\in \\Delta(E)$ such that $\\operatorname{supp}\\left(\\sigma^{2^*}\\right) \\subseteq M$ and\n",
    "$$\n",
    "\\max _{v \\in N} u\\left(v, \\sigma^{2^*}\\right) \\leq \\frac{1}{\\sum_{(i, j) \\in M} 1 / p_{i j}}\n",
    "$$\n",
    "\n",
    "Justify that the mixed strategy $\\sigma^{2^*}$ you consider is indeed a probability distribution.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "We know, that $u(v,(i,j))=p_{ij}\\mathbb{1}\\left\\{v=1\\text{ or }v=j\\right\\}$. Furthermore, player $p_2$ wants to minimize this utility. In a matching $M$, $p_2$ only chooses from $(i,j) \\in M$. Thus, their strategy distributes probability mass over these edges s.t.:\n",
    "\n",
    "\\begin{equation}\n",
    "    u(v, \\sigma^2) = \\sum_{(i,j) \\in M} \\sigma^2_{ij} p_{ij} \\mathbb{1}\\left\\{v=i \\text{ or } v=j\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "Now, let's assume that $\\sigma^{2*} = \\frac{\\frac{1}{p_{ij}}}{\\sum_{i \\in M} N_{ij}}$, then we have, that\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\min_{\\{\\sigma^2 \\in \\Delta(E)|\\text{supp}\\subseteq M\\}} \\max_{\\sigma^1 \\in \\Delta(N)} u(\\sigma^{1}, \\sigma^{2}) \\leq \\max_{v \\in N} u(v, \\sigma^{2*}) &= \\max_{v \\in N} \\sum_{(i,j) \\in M} \\sigma^{2*}_{ij} \\cdot u(v, (i,j))\\\\\n",
    "    &= \\max_{v \\in N} \\sum_{(i,j) \\in M} \\frac{\\frac{1}{\\textcolor{red}{\\cancel{\\textcolor{black}{p_{ij}}}}}}{\\sum\\limits_{(i,j) \\in M} \\frac{1}{p_{ij}}} \\cdot \\textcolor{red}{\\cancel{\\textcolor{black}{p_{ij}}}} u(v, (i,j))\\\\\n",
    "    &= \\frac{1}{\\sum\\limits_{(i,j) \\in M} \\frac{1}{p_{ij}}} \\max_{v \\in N} \\underbrace{\\sum_{(i,j) \\in M} \\mathbb{1}\\{v=i \\text{ or } v=j\\}}_{\\leq1}\n",
    "    \\leq \\frac{1}{\\sum\\limits_{(i,j) \\in M} \\frac{1}{p_{ij}}}\n",
    "\\end{aligned}\n",
    "\n",
    "Thus, our assumption about $\\sigma^{2*}$ holds and we can show, that $\\sigma^{2*}$ is indeed a probability distribution by reasoning that:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sum\\limits_{\\left(k,l\\right)\\in E} \\sigma^{2*}_{kl} = \\sum\\limits_{\\left(k,l\\right)\\in \\textcolor{purple}{M}} \\sigma^{2*}_{kl} = \\frac{\\sum\\limits_{\\left(k,l\\right)\\in M}\\frac{1}{p_{kl}}}{\\sum\\limits_{\\left(i,j\\right)\\in M}\\frac{1}{p_{ij}}} = 1 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b23178-ba8c-43f0-9e0d-2853028e693a",
   "metadata": {},
   "source": [
    "### b) (5 points)\n",
    "**Question**\n",
    "\n",
    "Formulate an Integer Program (IP) that minimizes the upper bound from Part (a), i.e. find a matching $M$ that maximizes $\\sum_{(i, j) \\in M} 1 / p_{i j}$\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Basically, just as in PS2, we want to find a maximum matching $M$ which, in this case, also incorporates the probability of a detection by the cop. Thus, we formulate the following LP:\n",
    "\n",
    "\\begin{aligned}\n",
    "& \\max _y \\sum_{(i j) \\in E} \\frac{1}{p_{i j}} y_{i j} \\\\\n",
    "& \\text { s.t. } \\sum_{\\{j \\in N \\mid(i, j) \\in E\\}}^i y_{i j} \\leq 1 \\quad \\forall i \\in N \\\\\n",
    "& \\\\\n",
    "& \\quad y_{i j} \\in\\{0,1\\}, \\quad \\forall(i, j) \\in E\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7da3b-9cc9-4212-8672-0735a3da09fd",
   "metadata": {},
   "source": [
    "### c) (4 points)\n",
    "\n",
    "**Question**\n",
    "\n",
    "Formulate the dual of the Linear Programming (LP) relaxation of the IP formulated in Part (b). Here, recall that LP relaxation means relaxing the integer variables taking values in $\\{0,1\\}$ and allowing them to take values $\\geq 0$. We denote its optimal value as $Z^*$. Before finding the dual problem, make sure to argue that the \" $\\leq 1$ \" constraint can be dropped from the primal LP.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "\n",
    "When we relax the constraint on $y_{ij}$ from being a binary variable to a continuous one, we have that $y_{ij}\\geq 0$ and $y_{ij}\\leq 1$. However, in this case, the latter constraint $y_{i j} \\leq 1$ can be dropped since we have constraint $\\sum_{\\{j \\in N \\mid(i, j) \\in E\\}}^i y_{i j} \\leq 1 \\quad \\forall i \\in N$. Thus, we are guaranteed that $y_{i j}$ is bounded from above and that the algorithm only chooses to set $y_{i j}$ to $\\geq 0$ (or activate it) if that increases the objective function. Furthermore, the objective function is uneffected if the constraint is removed. \n",
    "\n",
    "In the dual formulation, $\\mu_i$ and $\\mu_j$ represent a certain \"cost\" (in quotes as there is no attached unit or notion to this cost) of including the edge between nodes $i$ and $j$ for a matching. As we are *minimizing* this \"cost\" $\\mu_i+\\mu_j$ which is lower-bounded by $\\frac{1}{p_{ij}}$, the primal constraint of $y_{ij} \\leq 1$ is implicitly respected by the dual as well.\n",
    "\n",
    "Now, to take the dual, we first note that we need to relax the binary constraint on $y_{ij}$, converting these primal variables to a positive real-valued primal variable: \n",
    "\n",
    "\\begin{aligned}\n",
    "    \\mathcal{P}:\\quad& \\max _y \\sum_{(i j) \\in E} \\frac{1}{p_{i j}} y_{i j} \\\\\n",
    "    & \\text { s.t. } \\sum_{\\{j \\in N \\mid(i, j) \\in E\\}} y_{i j} \\leq 1 \\quad \\forall i \\in N \\\\\n",
    "    & \\\\\n",
    "    & \\quad y_{ij} \\geq 0, \\quad \\forall(i, j) \\in E\n",
    "\\end{aligned}\n",
    "\n",
    "Which we can re-write as:\n",
    "\n",
    "<center><img width=500 src=\"img/3_c.png\"/></center>\n",
    "\n",
    "And which we can then, using the dual variables $\\mu_i$ and $\\mu_j$, rewrite to the dual as:\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\mathcal{P}:\\quad &\\min _x \\sum_{i \\in N} \\mu_i \\\\\n",
    "                      &\\mu_i+\\mu_j \\geq \\frac{1}{p_{i j}} \\quad \\forall(i, j) \\in E \\\\\n",
    "                      &\\mu_i \\geq 0\n",
    "\\end{aligned}\n",
    "\n",
    "Note, that while $\\mu_i \\in \\mathbb{R}_{\\geq 0}$, $\\mu_j$ is unbounded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e8f44-e9c7-41fd-8b87-a3c3d2054344",
   "metadata": {},
   "source": [
    "### d) (8 points)\n",
    "\n",
    "**Question**\n",
    "\n",
    "Derive a mixed strategy $\\sigma^{1^*}$ for player 1 such that the probability with which player 2 is detected is at least $\\frac{1}{Z^*}$, regardless of player 2's strategy. Equivalently, find $\\sigma^{1^*} \\in \\Delta(N)$ such that\n",
    "\n",
    "\\begin{equation}\n",
    "    \\min _{(i, j) \\in E} u\\left(\\sigma^{1^*},(i, j)\\right) \\geq \\frac{1}{Z^*} .\n",
    "\\end{equation}\n",
    "\n",
    "Justify that the mixed strategy $\\sigma^{1^*}$ you consider is indeed a probability distribution.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Mixed strategy $\\sigma^{1*}$ for player $p_1$, such that probability of detection is $\\geq \\frac{1}{Z^*}$ regardless of their strategy, i.e., find\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma^{1*} \\in \\Delta(N) \\text { s.t. } \\min _{(i, j) \\in E} u\\left(\\sigma^{1*},(i, j)\\right) \\geq \\frac{1}{Z^*}\n",
    "\\end{equation}\n",
    "\n",
    "As we know, that $u(v, (i,j)) = p_{ij} \\mathbb{1}\\{v = i \\text{ or } v = j\\}$, let's formulate:\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\min_{(i,j) \\in E} u(\\sigma^{1*}, (i,j)) &= \\sum_{v \\in N} \\sigma_v^* \\cdot u(v,(i,j))\\\\\n",
    "                                     &= \\sum_{v \\in N} \\sigma_v^* \\cdot p_{ij} \\cdot \\mathbb{1}\\{v = i \\text{ or } v = j\\}\n",
    "\\end{aligned}\n",
    "\n",
    "Since we are summing over all nodes $v \\in N$, we know, that $\\sum_{v \\in N} \\mathbb{1}\\{v=i$ or $v=j\\}=1$ and will be composed of two parts, due to the \"OR\":\n",
    "\n",
    "$\\sum_{v \\in N} \\mathbb{1}\\{v=i$ or $v=j\\}=\\sum_{v \\in N}^1 \\mathbb{1}\\{v=i\\}+\\sum_{v \\in N}^1 \\mathbb{1}\\{v=j\\}$  \n",
    "\n",
    "We can therefore proceed by reasoning:\n",
    "\n",
    "\\begin{equation}\n",
    " \\min_{(i,j) \\in E} u(\\sigma^{1*}, (i,j)) = \\min _{(i, j) \\in E} \\quad \\sum_{v \\in N} p_{i j}\\left(\\sigma_i^{1*}+\\sigma_j^{1*}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Let $\\sigma_v^{1 *}=\\frac{\\mu_v^*}{Z^*}$, where $\\left\\{\\mu_v^*;\\forall_{v \\in} N\\right\\}=\\boldsymbol{\\mu^*}$ is the optimal solution of the dual we defined above. Then, we have:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\min_{(i,j) \\in E} u(\\sigma^{1*}, (i,j)) &=p_{i j}\\left(\\frac{\\mu_i^*}{Z^*}+\\frac{\\mu_j^*}{Z^*}\\right) \\\\\n",
    "                                         &=p_{i j}\\left(\\mu_i^*+\\mu_j^*\\right) \\frac{1}{Z^*} \\\\\n",
    "                                         &\\geq \\frac{1}{Z^*}\n",
    "\\end{aligned}\n",
    "\n",
    "Since we know, that $0 \\leqslant p_{i j} \\leqslant 1$, $\\sum\\limits_{\\left(i,j\\right)\\in E} p_{i j}=1$, and $\\mu_i+\\mu_j \\geqslant \\frac{1}{p_{i j}}, \\forall(i, j) \\in E$ we have that \n",
    "\n",
    "\\begin{equation}\n",
    "    p_{i j}\\left(\\mu_i^*+\\mu_j^*\\right) \\geqslant 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bee16e-819e-41ca-9aa7-2c873440195f",
   "metadata": {},
   "source": [
    "### e)\n",
    "\n",
    "**Question**\n",
    "\n",
    "\n",
    "\n",
    "**Answer**\n",
    "\n",
    "From PS2 we know, that the cop and the robber play a bipartite graph matching game which is still the cave. Thess, we consider an adapted version of Maximum set cover aus l the minimum vertex cover, that we have preciously shown to make resets. From the above, we have that the maximum matching $\\mu^*$ produces the optimal solution for both players and, given total unimodubarity of the constraints and by strong duality, we can reason, that:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\frac{1}{Z^*} \\leq \\min _{(i, j) \\in E} u\\left(\\sigma^{1*},(i, j)\\right) &\\leq \\max _{\\sigma^{1} \\in \\Delta(N)} \\min _{\\sigma^2 \\in \\Delta(E)} u\\left(\\sigma^{1}, \\sigma^2\\right) \\\\\n",
    "    & =\\min_{\\sigma^2 \\in \\Delta(E)} \\quad \\max_{\\sigma^{1} \\in \\Delta(N)} u\\left(\\sigma^{1}, \\sigma^2\\right) \\leq \\max _{v \\in N} u\\left(v, \\sigma^{2^*}\\right) \\leq \\frac{1}{\\sum\\limits_{\\left(i,j \\right) \\in M^*} \\frac{1}{p_{i j}}}=\\frac{1}{Z^*}\n",
    "\\end{aligned}\n",
    "\n",
    "Since $\\Gamma$ is a zero-sum game, we can conclude, that $\\left(\\sigma^{1^*}, \\sigma^{2^*}\\right)$ is an NE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad409cf-2efe-4da4-9e44-a1a98f40b07a",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## Code for Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0654d-89f3-4f86-9056-842ace440a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Dec 4\n",
    "As part of the Problem Set 3 for Resilient Network (1.208) course at MIT\n",
    "\n",
    "@author: Riccardo Fiorista\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import Setting\n",
    "from ProblemData import dat\n",
    "import Modules\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, quicksum\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "# Create the parser\n",
    "parser = argparse.ArgumentParser(description='Run EVPI and SVV computations')\n",
    "\n",
    "# Add arguments\n",
    "parser.add_argument('n_scenarios', metavar='N', type=int,\n",
    "                    help='an integer for the number of scenarios')\n",
    "parser.add_argument('--mode', dest='mode',\n",
    "                    help='sum the integers (default: find the max)')\n",
    "\n",
    "# Parse arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "sTime = time.time()\n",
    "\n",
    "# %% set settings\n",
    "Setting.dataFolder = 'Data'\n",
    "Setting.num_locations = 6\n",
    "Setting.num_days = 10  # first N time periods, up to 365\n",
    "Setting.num_scen = args.n_scenarios\n",
    "\n",
    "# do not change the following parameters and settings.\n",
    "Setting.solver_gap = 0.001  # x100 percent\n",
    "Setting.wall_clock_time_lim = 3600 * 2  # seconds\n",
    "Setting.load_shedding_cost = 1e4\n",
    "Setting.plant_types = ['CCGT', 'solar-UPV', 'wind-new']\n",
    "Setting.load_range = np.array([150, 220]) * 1e6\n",
    "Setting.plant_lim_range = np.array([400, 600])\n",
    "Setting.RPS = 0.0\n",
    "# %% fetch data\n",
    "dat.PopulateDataClass()\n",
    "\n",
    "\n",
    "class DVs:\n",
    "    X = []\n",
    "    prod = []\n",
    "    s1Obj = []\n",
    "    s2Obj = []\n",
    "    shed = []\n",
    "    X_val = []\n",
    "    prod_val = []\n",
    "\n",
    "\n",
    "def compute_evpi():\n",
    "    z_star = Modules.solve_Exensive_form(DVs, 0)\n",
    "    print(f\"{z_star=}\")\n",
    "    theta = 0\n",
    "\n",
    "    for s in range(Setting.num_scen):\n",
    "        Model = gp.Model()\n",
    "\n",
    "        DVs.X = Model.addVars(dat.nP, dat.nN, vtype=GRB.INTEGER)\n",
    "        DVs.prod = Model.addVars(dat.nP, dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "        DVs.shed = Model.addVars(dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "        DVs.s1Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "        DVs.s2Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "\n",
    "        obj1 = quicksum(\n",
    "            (dat.Plants[i].amor_capex + dat.Plants[i].FOM) * DVs.X[i, n] for i in range(dat.nP) for n in range(dat.nN))\n",
    "        Model.addConstr(DVs.s1Obj == obj1)\n",
    "        Model.addConstr(DVs.s1Obj == obj1)\n",
    "\n",
    "        obj2 = quicksum(\n",
    "            dat.Plants[i].VOM * DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in\n",
    "            range(dat.nT))\n",
    "        obj2 += quicksum(\n",
    "            Setting.load_shedding_cost * DVs.shed[n, t] for n in range(dat.nN) for t in range(dat.nT))\n",
    "        Model.addConstr(DVs.s2Obj == obj2)\n",
    "\n",
    "        Model.modelSense = GRB.MINIMIZE\n",
    "        Model.setObjective(obj1 + DVs.s2Obj)\n",
    "\n",
    "        # constraints\n",
    "        Model.addConstrs(DVs.X[i, n] <= dat.Nodes[n].plant_lim[i] for i in range(dat.nP) for n in range(dat.nN))\n",
    "\n",
    "        Model.addConstrs(\n",
    "            DVs.prod[i, n, t] <= dat.Plants[i].cap_factor[t] * dat.Plants[i].nameplate_cap * DVs.X[i, n] for i in\n",
    "            range(dat.nP) for n in range(dat.nN) for t in range(dat.nT))\n",
    "        Model.addConstrs(\n",
    "            quicksum(DVs.prod[i, n, t] for i in range(dat.nP)) + DVs.shed[n, t] == dat.Nodes[n].load[t, s] for\n",
    "            n\n",
    "            in range(dat.nN) for t in range(dat.nT))\n",
    "        Model.addConstr(quicksum(\n",
    "            DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in range(dat.nT) if\n",
    "            dat.Plants[i].Type != 'CCGT') >= Setting.RPS * quicksum(\n",
    "            dat.Nodes[n].load[t, s] for n in range(dat.nN) for t in range(dat.nT)))\n",
    "\n",
    "        Model.setParam('OutputFlag', 0)\n",
    "        Model.setParam('MIPGap', Setting.solver_gap)\n",
    "        Model.setParam('Timelimit', Setting.wall_clock_time_lim)\n",
    "\n",
    "        Model.optimize()\n",
    "\n",
    "        result = Model.ObjVal\n",
    "        print(result)\n",
    "        theta += dat.probs[s] * result\n",
    "\n",
    "    return (z_star - theta) / z_star\n",
    "\n",
    "\n",
    "def compute_vss():\n",
    "    z_star = Modules.solve_Exensive_form(DVs, 0)\n",
    "    print(z_star)\n",
    "\n",
    "    ###############################################\n",
    "    # Compute z with avg \\xi\n",
    "    ###############################################\n",
    "    xi_mean = {(n, t): np.mean(dat.Nodes[n].load[t, :]) for t in range(dat.nT) for n in range(dat.nN)}\n",
    "    print(\"Xi mean:\", xi_mean)\n",
    "\n",
    "    Model = gp.Model()\n",
    "\n",
    "    DVs.X = Model.addVars(dat.nP, dat.nN, vtype=GRB.INTEGER)\n",
    "    DVs.prod = Model.addVars(dat.nP, dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "    DVs.shed = Model.addVars(dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "    DVs.s1Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "    DVs.s2Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "\n",
    "    obj1 = quicksum(\n",
    "        (dat.Plants[i].amor_capex + dat.Plants[i].FOM) * DVs.X[i, n] for i in range(dat.nP) for n in range(dat.nN))\n",
    "    Model.addConstr(DVs.s1Obj == obj1)\n",
    "\n",
    "    obj2 = quicksum(\n",
    "        dat.Plants[i].VOM * DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in\n",
    "        range(dat.nT))\n",
    "    obj2 += quicksum(\n",
    "        Setting.load_shedding_cost * DVs.shed[n, t] for n in range(dat.nN) for t in range(dat.nT))\n",
    "    Model.addConstr(DVs.s2Obj == obj2)\n",
    "\n",
    "    Model.modelSense = GRB.MINIMIZE\n",
    "    Model.setObjective(obj1 + DVs.s2Obj)\n",
    "\n",
    "    # constraints\n",
    "    Model.addConstrs(DVs.X[i, n] <= dat.Nodes[n].plant_lim[i] for i in range(dat.nP) for n in range(dat.nN))\n",
    "\n",
    "    Model.addConstrs(\n",
    "        DVs.prod[i, n, t] <= dat.Plants[i].cap_factor[t] * dat.Plants[i].nameplate_cap * DVs.X[i, n] for i in\n",
    "        range(dat.nP) for n in range(dat.nN) for t in range(dat.nT))\n",
    "    Model.addConstrs(\n",
    "        quicksum(DVs.prod[i, n, t] for i in range(dat.nP)) + DVs.shed[n, t] == xi_mean[n,t] for n in range(dat.nN) for t in range(dat.nT))\n",
    "    Model.addConstr(quicksum(\n",
    "        DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in range(dat.nT) if\n",
    "        dat.Plants[i].Type != 'CCGT') >= Setting.RPS * quicksum(\n",
    "        xi_mean[n, t] for n in range(dat.nN) for t in range(dat.nT)))\n",
    "\n",
    "    Model.setParam('OutputFlag', 0)\n",
    "    Model.setParam('MIPGap', Setting.solver_gap)\n",
    "    Model.setParam('Timelimit', Setting.wall_clock_time_lim)\n",
    "\n",
    "    Model.optimize()\n",
    "\n",
    "    DVs.X_val = Model.getAttr('x', DVs.X)\n",
    "\n",
    "    print(\"Avg Xi Model Obj:\", Model.ObjVal)\n",
    "\n",
    "    ###############################################\n",
    "    ###############################################\n",
    "\n",
    "    x_star = copy.deepcopy(DVs.X_val)\n",
    "\n",
    "    theta = 0\n",
    "\n",
    "    for s in range(Setting.num_scen):\n",
    "        Model = gp.Model()\n",
    "\n",
    "        DVs.prod = Model.addVars(dat.nP, dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "        DVs.shed = Model.addVars(dat.nN, dat.nT, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "        DVs.s1Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "        DVs.s2Obj = Model.addVar(vtype=GRB.CONTINUOUS)\n",
    "\n",
    "        obj1 = quicksum(\n",
    "            (dat.Plants[i].amor_capex + dat.Plants[i].FOM) * x_star[i, n] for i in range(dat.nP) for n in range(dat.nN))\n",
    "        Model.addConstr(DVs.s1Obj == obj1)\n",
    "\n",
    "        obj2 = quicksum(\n",
    "            dat.Plants[i].VOM * DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in\n",
    "            range(dat.nT))\n",
    "        obj2 += quicksum(\n",
    "            Setting.load_shedding_cost * DVs.shed[n, t] for n in range(dat.nN) for t in range(dat.nT))\n",
    "\n",
    "        Model.addConstr(DVs.s2Obj == obj2)\n",
    "        Model.modelSense = GRB.MINIMIZE\n",
    "        Model.setObjective(obj1 + DVs.s2Obj)\n",
    "\n",
    "        # constraints\n",
    "        # Model.addConstrs(x_star[i, n] <= dat.Nodes[n].plant_lim[i] for i in range(dat.nP) for n in range(dat.nN))\n",
    "\n",
    "        Model.addConstrs(\n",
    "            DVs.prod[i, n, t] <= dat.Plants[i].cap_factor[t] * dat.Plants[i].nameplate_cap * x_star[i, n] for i in\n",
    "            range(dat.nP) for n in range(dat.nN) for t in range(dat.nT))\n",
    "        Model.addConstrs(\n",
    "            quicksum(DVs.prod[i, n, t] for i in range(dat.nP)) + DVs.shed[n, t] == dat.Nodes[n].load[t, s] for\n",
    "            n\n",
    "            in range(dat.nN) for t in range(dat.nT))\n",
    "        Model.addConstr(quicksum(\n",
    "            DVs.prod[i, n, t] for i in range(dat.nP) for n in range(dat.nN) for t in range(dat.nT) if\n",
    "            dat.Plants[i].Type != 'CCGT') >= Setting.RPS * quicksum(\n",
    "            dat.Nodes[n].load[t, s] for n in range(dat.nN) for t in range(dat.nT)))\n",
    "\n",
    "        Model.setParam('OutputFlag', 0)\n",
    "        Model.setParam('MIPGap', Setting.solver_gap)\n",
    "        Model.setParam('Timelimit', Setting.wall_clock_time_lim)\n",
    "\n",
    "        Model.optimize()\n",
    "\n",
    "        DVs.prod_val = Model.getAttr('x', DVs.prod)\n",
    "        DVs.shed_val = Model.getAttr('x', DVs.shed)\n",
    "\n",
    "        result = Model.ObjVal\n",
    "        print(result)\n",
    "        theta += dat.probs[s] * result\n",
    "\n",
    "    return (theta - z_star) / z_star\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if args.mode == \"EVPI\":\n",
    "        print(\"EVPI:\", compute_evpi())\n",
    "    elif args.mode == \"VSS\":\n",
    "        print(\"VSS:\", compute_vss())\n",
    "    else:\n",
    "        print('Mode not supported')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43f8bf-f5af-4071-80ca-234bb9fda0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Dec 4\n",
    "As part of the Problem Set 3 for Resilient Network (1.208) course at MIT\n",
    "\n",
    "@author: Riccardo Fiorista\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "# Function to call runner.py with subprocess\n",
    "def call_runner(n_scenarios, mode):\n",
    "    # Construct the command to run runner.py with arguments\n",
    "    command = ['python', 'Exercise.py', str(n_scenarios), '--mode', mode]\n",
    "\n",
    "    # Call the command\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Get the last line of the output\n",
    "    last_line = result.stdout.strip().split('\\n')[-1]\n",
    "    print(last_line)\n",
    "    # Attempt to convert the last line to a float\n",
    "    try:\n",
    "        last_line_float = float(last_line.strip().split(' ')[-1])\n",
    "        # print(f\"The last line as a float is: {last_line_float}\")\n",
    "        return last_line_float\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not convert the last line to float: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_function(bns):\n",
    "    return (call_runner(bns, 'EVPI'), call_runner(bns, 'VSS'))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    big_n_scenarios = list(range(10, 41))\n",
    "\n",
    "    # Define the number of processes to use\n",
    "    num_processes = multiprocessing.cpu_count()  # Or set a specific number\n",
    "\n",
    "    # Create a Pool of workers\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = list(pool.imap(process_function, big_n_scenarios))\n",
    "\n",
    "    # Unpack results\n",
    "    evpis = [result[0] for result in results]\n",
    "    vss_s = [result[1] for result in results]\n",
    "\n",
    "    print(\"EVPIs:\", evpis)\n",
    "    print(\"VSSs:\", vss_s)\n",
    "\n",
    "    plt.plot(big_n_scenarios, evpis, c='red', label=\"EVPI\")\n",
    "    plt.scatter(big_n_scenarios, evpis, c='red')\n",
    "\n",
    "    plt.plot(big_n_scenarios, vss_s, c='blue', label=\"VSS\")\n",
    "    plt.scatter(big_n_scenarios, vss_s, c='blue')\n",
    "    plt.legend()\n",
    "    plt.title(\"EVPIS and VSS Over Scenarios\")\n",
    "    plt.xlabel(\"# Scenarios\")\n",
    "    plt.ylabel(\"EVPIS/VSS\")\n",
    "    plt.savefig(f\"run_{time.time()}.svg\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
