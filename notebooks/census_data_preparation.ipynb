{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "2033543a5bd70d17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BASE_PATH = Path('/home/rico/Documents/courses/6.C571/Final Project/ernp/data/Boston')\n",
    "city = \"Boston\"\n",
    "country = \"US\"\n",
    "osm_poi_tags = {'amenity':'school'}\n",
    "poi_file = BASE_PATH / \"boston_pois.geojson\"\n",
    "gtfs_file = BASE_PATH / \"mbta_transit_feed.zip\"\n",
    "crs = \"EPSG:4326\""
   ],
   "id": "66f4e3f92c792224"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Census Data",
   "id": "158ff8e439ac51d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# towns_gdf = gpd.read_file(BASE_PATH / \"CENSUS2020TOWNS_SHP/CENSUS2020TOWNS_POLY.shp\")\n",
    "# towns_gdf['GEOID20'] = towns_gdf['GEOID20'].astype(str)\n",
    "# towns_gdf['PLACE_GEOID20'] = towns_gdf['GEOID20'].str[:7].astype(str)\n",
    "census_blocks_gdf = gpd.read_file(BASE_PATH / 'CENSUS2020_BLK_BG_TRCT/CENSUS2020BLOCKS_POLY.shp')\n",
    "census_blocks_gdf['GEOID20'] = census_blocks_gdf['GEOID20'].astype(str)\n",
    "census_bgs_gdf = gpd.read_file(BASE_PATH / 'CENSUS2020_BLK_BG_TRCT/CENSUS2020BLOCKGROUPS_POLY.shp')\n",
    "census_bgs_gdf['GEOID20'] = census_bgs_gdf['GEOID20'].astype(str)\n",
    "# census_bgs_gdf['PLACE_GEOID20'] = census_bgs_gdf['GEOID20'].str[:7].astype(str)\n",
    "merged_df = gpd.sjoin(census_bgs_gdf, census_blocks_gdf[['geometry', 'TOWN']], how='left', predicate='intersects')\n",
    "merged_df = merged_df[[col for col in merged_df.columns if 'block' not in col]]\n",
    "merged_df = merged_df[['STATEFP20', 'COUNTYFP20', 'TRACTCE20', 'BLKGRPCE20', 'GEOID20',\n",
    "                       'NAMELSAD20', 'MTFCC20', 'ALAND20', 'AWATER20', 'INTPTLAT20',\n",
    "                       'INTPTLON20', 'AREA_SQFT', 'AREA_ACRES', 'TRACT20', 'HOUSING20',\n",
    "                       'POP20', 'BLK20_CNT', 'SHAPE_AREA', 'SHAPE_LEN', 'TOWN', 'geometry']]\n",
    "merged_df = merged_df.drop_duplicates(subset='GEOID20')\n",
    "# merged_df.explore()\n",
    "# Load the MBTA communities excel file\n",
    "mbta_communities = pd.read_excel(BASE_PATH / \"mbta_communities.xlsx\")\n",
    "mbta_communities['Municipality'] = mbta_communities['Municipality'].str.upper()\n",
    "filtered_merged_df = merged_df[merged_df['TOWN'].isin(mbta_communities['Municipality'].to_list() + ['BOSTON'])]\n",
    "filtered_merged_df = filtered_merged_df.merge(mbta_communities[['Municipality', 'MBTA Community Type']], left_on='TOWN',\n",
    "                                              right_on='Municipality', how='left')\n",
    "filtered_merged_df = filtered_merged_df.drop(columns='Municipality')\n",
    "filtered_merged_df.loc[filtered_merged_df['MBTA Community Type'].isna(), 'MBTA Community Type'] = 'subway or light rail'\n",
    "filtered_merged_df.shape\n",
    "filtered_merged_df.explore()\n",
    "filtered_merged_df.head(5)\n",
    "# ACS data\n",
    "acs_gdf = pd.read_csv(BASE_PATH / 'acs_2022.csv', skiprows=0)\n",
    "# Remove first row\n",
    "acs_gdf = acs_gdf.drop(0)\n",
    "# Assuming your ACS data is in a DataFrame called `acs_df`\n",
    "acs_gdf['State FIPS'] = acs_gdf['State (FIPS Code)'].astype(str).str.zfill(2)\n",
    "acs_gdf['County FIPS'] = acs_gdf['County of current residence'].astype(str).str.zfill(3)\n",
    "acs_gdf['Census Tract'] = acs_gdf['Census Tract'].astype(str).str.zfill(6)\n",
    "acs_gdf['Block Group'] = acs_gdf['Block Group'].astype(str).str.zfill(1)\n",
    "\n",
    "# Create GEOID20 for Block Group\n",
    "acs_gdf['GEOID20'] = (\n",
    "        acs_gdf['State FIPS'] +\n",
    "        acs_gdf['County FIPS'] +\n",
    "        acs_gdf['Census Tract'] +\n",
    "        acs_gdf['Block Group']\n",
    ")\n",
    "str_columns = [\n",
    "    'Qualifying Name',\n",
    "    'GEOID20',\n",
    "]\n",
    "\n",
    "int_columns = [\n",
    "    # Denomenator for income categories\n",
    "    'Households:',\n",
    "    'Households: Less than $25,000',\n",
    "    'Households: $25,000 to $49,999',\n",
    "    'Households: $50,000 to $74,999',\n",
    "    'Households: $75,000 to $99,999',\n",
    "    'Households: $100,000 or More',\n",
    "\n",
    "    # This is the total population of the census tract (count)\n",
    "    'Total Population',\n",
    "    # Denominator for age categories beginning with male\n",
    "    'Total Population: Male',\n",
    "    'Total Population: Male: Under 18 Years',\n",
    "    'Total Population: Male: 18 to 34 Years',\n",
    "    'Total Population: Male: 35 to 64 Years',\n",
    "    'Total Population: Male: 65 Years and Over',\n",
    "    # Denominator for age categories beginning with female\n",
    "    'Total Population: Female',\n",
    "    'Total Population: Female: Under 18 Years',\n",
    "    'Total Population: Female: 18 to 34 Years',\n",
    "    'Total Population: Female: 35 to 64 Years',\n",
    "    'Total Population: Female: 65 Years and Over',\n",
    "\n",
    "    # Merging all racial categories within \"Hispanic and Latino\" so that\n",
    "    # there aren't an overwhelming number of racial categories \n",
    "    'Total Population: Hispanic or Latino',\n",
    "    'Total Population: Not Hispanic or Latino',\n",
    "    'Total Population: Not Hispanic or Latino: White Alone',\n",
    "    'Total Population: Not Hispanic or Latino: Black or African American Alone',\n",
    "    'Total Population: Not Hispanic or Latino: American Indian and Alaska Native Alone',\n",
    "    'Total Population: Not Hispanic or Latino: Asian Alone',\n",
    "    'Total Population: Not Hispanic or Latino: Native Hawaiian and Other Pacific Islander Alone',\n",
    "    'Total Population: Not Hispanic or Latino: Some Other Race Alone',\n",
    "    'Total Population: Not Hispanic or Latino: Two or More Races',\n",
    "\n",
    "    'Workers 16 Years and Over:',\n",
    "    'Workers 16 Years and Over: Car, Truck, or Van',\n",
    "    'Workers 16 Years and Over: Drove Alone',\n",
    "    'Workers 16 Years and Over: Public Transportation (Includes Taxicab)',\n",
    "    'Workers 16 Years and Over: Motorcycle',\n",
    "    'Workers 16 Years and Over: Bicycle',\n",
    "    'Workers 16 Years and Over: Walked',\n",
    "    'Workers 16 Years and Over: Other Means',\n",
    "    'Workers 16 Years and Over: Worked At Home',\n",
    "\n",
    "    'Occupied Housing Units: No Vehicle Available',\n",
    "    'Occupied Housing Units: 1 Vehicle Available',\n",
    "    'Occupied Housing Units: 2 Vehicles Available',\n",
    "]\n",
    "\n",
    "float_columns = [\n",
    "    'Area Total:',\n",
    "    'Area (Land)',\n",
    "    'Area (Water)',\n",
    "    'Population Density (Per Sq. Mile)',\n",
    "    'Median Household Income (In 2022 Inflation Adjusted Dollars)',\n",
    "]\n",
    "\n",
    "columns_to_include = str_columns + int_columns + float_columns\n",
    "filtered_acs_gdf = acs_gdf[columns_to_include]\n",
    "\n",
    "filtered_acs_gdf.loc[\n",
    "    filtered_acs_gdf['Population Density (Per Sq. Mile)'].isna(), 'Population Density (Per Sq. Mile)'] = \\\n",
    "filtered_acs_gdf['Total Population'].astype(int) / filtered_acs_gdf['Area Total:'].astype(float)\n",
    "# filtered_acs_gdf.loc[filtered_acs_gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'].isna(), 'Median Household Income (In 2022 Inflation Adjusted Dollars)'] = -1\n",
    "complete_census = filtered_merged_df.merge(filtered_acs_gdf, on='GEOID20', how='left')\n",
    "# Load your GeoDataFrame\n",
    "gdf = complete_census  # Assuming this is your loaded GeoDataFrame\n",
    "\n",
    "# Ensure the column for Median Household Income is numeric\n",
    "gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'] = pd.to_numeric(\n",
    "    gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Mark -1 as NaN to identify missing data\n",
    "gdf.loc[gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'] == -1,\n",
    "'Median Household Income (In 2022 Inflation Adjusted Dollars)'] = np.nan\n",
    "\n",
    "# Find block groups with NaN in the target column\n",
    "missing_income = gdf[gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'].isna()]\n",
    "\n",
    "# Spatial join to find neighbors\n",
    "gdf['geometry'] = gdf['geometry'].buffer(0)  # Fix potential invalid geometries\n",
    "# Perform spatial join and ensure correct columns\n",
    "neighbors = gpd.sjoin(gdf, gdf, how='inner', predicate='touches', lsuffix='left', rsuffix='right')\n",
    "\n",
    "\n",
    "# Define a function to calculate the average of neighboring block groups\n",
    "def spatially_fill_missing_values(row, column_name, neighbors_df):\n",
    "    neighbors_of_row = neighbors_df[neighbors_df.index == row.name]\n",
    "    neighboring_values = gdf.loc[neighbors_of_row['index_right'], column_name]\n",
    "    valid_values = neighboring_values[neighboring_values.notna()]\n",
    "    return valid_values.mean() if not valid_values.empty else 0\n",
    "\n",
    "\n",
    "# Fill missing income values\n",
    "gdf['Median Household Income (In 2022 Inflation Adjusted Dollars)'] = gdf.apply(\n",
    "    lambda row: spatially_fill_missing_values(\n",
    "        row,\n",
    "        'Median Household Income (In 2022 Inflation Adjusted Dollars)',\n",
    "        neighbors\n",
    "    ) if pd.isna(row['Median Household Income (In 2022 Inflation Adjusted Dollars)'])\n",
    "    else row['Median Household Income (In 2022 Inflation Adjusted Dollars)'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Coerce into types\n",
    "gdf[str_columns] = gdf[str_columns].astype(str)\n",
    "gdf[int_columns] = gdf[int_columns].astype(int)\n",
    "gdf[float_columns] = gdf[float_columns].astype(float)\n",
    "gdf['res_centroid'] = gpd.points_from_xy(gdf['INTPTLON20'], gdf['INTPTLAT20'], crs=crs)"
   ],
   "id": "c49dc40b6ea2c226"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "gdf.to_parquet(BASE_PATH / 'complete_census_2022.parquet')",
   "id": "70c8acdecdec2c85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
